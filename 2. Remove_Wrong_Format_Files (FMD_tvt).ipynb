{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, GlobalMaxPooling2D\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "SEED = 42\n",
    "import random \n",
    "random.seed(SEED)\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** Inputs ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Folder that needs to be \"cleaned\"\n",
    "image_folder_name = 'FMD_tvt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup Paths and Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fabric', 'foliage', 'glass', 'leather', 'metal', 'paper', 'plastic', 'stone', 'water', 'wood']\n"
     ]
    }
   ],
   "source": [
    "tvt_folders = ['train', 'val', 'test']\n",
    "im_folders = ['image', 'mask']\n",
    "\n",
    "Fmd_class_path = os.path.join(image_folder_name, tvt_folders[0], im_folders[0])\n",
    "classes = os.listdir(os.path.join(Fmd_class_path))\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path_train = os.path.join(image_folder_name, tvt_folders[0], im_folders[0])\n",
    "mask_path_train = os.path.join(image_folder_name, tvt_folders[0], im_folders[1])\n",
    "\n",
    "image_path_val = os.path.join(image_folder_name, tvt_folders[1], im_folders[0])\n",
    "mask_path_val = os.path.join(image_folder_name, tvt_folders[1], im_folders[1])\n",
    "\n",
    "image_path_test = os.path.join(image_folder_name, tvt_folders[2], im_folders[0])\n",
    "mask_path_test = os.path.join(image_folder_name, tvt_folders[2], im_folders[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train got it\n"
     ]
    }
   ],
   "source": [
    "for tvt in tvt_folders:\n",
    "    if os.path.exists(os.path.join(image_folder_name, tvt, im_folders[0], classes[1], 'Thumbs.db')):\n",
    "        print(tvt, 'got it')\n",
    "        os.remove(os.path.join(image_folder_name, tvt, im_folders[0], classes[1], 'Thumbs.db'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all names together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599\n"
     ]
    }
   ],
   "source": [
    "names_train = []\n",
    "for class_ in classes:\n",
    "    img_names = os.listdir(os.path.join(image_path_train, class_))\n",
    "    names_train = names_train + img_names\n",
    "    for name in img_names:\n",
    "        img = cv2.imread(os.path.join(image_path_train, class_, name))\n",
    "\n",
    "print(len(names_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "names_val = []\n",
    "for class_ in classes:\n",
    "    img_names = os.listdir(os.path.join(image_path_val, class_))\n",
    "    names_val = names_val + img_names\n",
    "    for name in img_names:\n",
    "        img = cv2.imread(os.path.join(image_path_val, class_, name))\n",
    "\n",
    "print(len(names_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201\n"
     ]
    }
   ],
   "source": [
    "names_test = []\n",
    "for class_ in classes:\n",
    "    img_names = os.listdir(os.path.join(image_path_test, class_))\n",
    "    names_test = names_test + img_names\n",
    "    for name in img_names:\n",
    "        img = cv2.imread(os.path.join(image_path_test, class_, name))\n",
    "\n",
    "print(len(names_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Images in Tensorflow format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_load_image(x):\n",
    "    byte_img = tf.io.read_file(x) #Tensorflow way of loading in image\n",
    "    img = tf.io.decode_jpeg(byte_img)  #Need both lines of code\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all the names images\n",
    "train_ds = tf.data.Dataset.list_files(os.path.join(image_folder_name, tvt_folders[0], im_folders[0], classes[0], \"*.jpg\"), shuffle=False)\n",
    "for i in range(len(classes)-1):\n",
    "    train_ds_class = tf.data.Dataset.list_files(os.path.join(image_folder_name, tvt_folders[0], im_folders[0], classes[i + 1], \"*.jpg\"), shuffle=False)\n",
    "    train_ds = train_ds.concatenate(train_ds_class)\n",
    "\n",
    "train_ds = train_ds.map(fun_load_image)\n",
    "train_ds = train_ds.map(lambda x: tf.image.resize(x, (150,150)))\n",
    "train_ds = train_ds.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all the names images\n",
    "val_ds = tf.data.Dataset.list_files(os.path.join(image_folder_name, tvt_folders[1], im_folders[0], classes[0], \"*.jpg\"), shuffle=False)\n",
    "for i in range(len(classes)-1):\n",
    "    val_ds_class = tf.data.Dataset.list_files(os.path.join(image_folder_name, tvt_folders[1], im_folders[0], classes[i + 1], \"*.jpg\"), shuffle=False)\n",
    "    val_ds = val_ds.concatenate(val_ds_class)\n",
    "\n",
    "val_ds = val_ds.map(fun_load_image)\n",
    "val_ds = val_ds.map(lambda x: tf.image.resize(x, (150,150)))\n",
    "val_ds = val_ds.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.data.Dataset.list_files(os.path.join(image_folder_name, tvt_folders[2], im_folders[0], classes[0], \"*.jpg\"), shuffle=False)\n",
    "for i in range(len(classes)-1):\n",
    "    test_ds_class = tf.data.Dataset.list_files(os.path.join(image_folder_name, tvt_folders[2], im_folders[0], classes[i + 1], \"*.jpg\"), shuffle=False)\n",
    "    test_ds = test_ds.concatenate(test_ds_class)\n",
    "\n",
    "test_ds = test_ds.map(fun_load_image)\n",
    "test_ds = test_ds.map(lambda x: tf.image.resize(x, (150,150)))\n",
    "test_ds = test_ds.map(lambda x: x/255)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Non RGB Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 150, 1) 190\n",
      "(150, 150, 1) 482\n",
      "[190, 482]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "removes_no_RGB_train = []\n",
    "for elem in train_ds:\n",
    "    if np.shape(elem.numpy()) != (150, 150, 3):\n",
    "        print(np.shape(elem.numpy()), i)\n",
    "        removes_no_RGB_train.append(i)\n",
    "    i =  i + 1\n",
    "\n",
    "print(removes_no_RGB_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "removes_no_RGB_val = []\n",
    "for elem in val_ds:\n",
    "    if np.shape(elem.numpy()) != (150, 150, 3):\n",
    "        print(np.shape(elem.numpy()), i)\n",
    "        removes_no_RGB_val.append(i)\n",
    "    i =  i + 1\n",
    "\n",
    "print(removes_no_RGB_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 150, 1) 47\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "removes_no_RGB_test = []\n",
    "for elem in test_ds:\n",
    "    if np.shape(elem.numpy()) != (150, 150, 3):\n",
    "        print(np.shape(elem.numpy()), i)\n",
    "        removes_no_RGB_test.append(i)\n",
    "    i =  i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['leather_moderate_022_new.jpg', 'water_moderate_007_new.jpg']\n"
     ]
    }
   ],
   "source": [
    "remove_names_train = []\n",
    "for idx in removes_no_RGB_train:\n",
    "    remove_name = names_train[idx]\n",
    "    remove_names_train.append(remove_name)\n",
    "\n",
    "print(remove_names_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "remove_names_val = []\n",
    "for idx in removes_no_RGB_val:\n",
    "    remove_name = names_val[idx]\n",
    "    remove_names_val.append(remove_name)\n",
    "\n",
    "print(remove_names_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['glass_moderate_029_new.jpg']\n"
     ]
    }
   ],
   "source": [
    "remove_names_test = []\n",
    "for idx in removes_no_RGB_test:\n",
    "    remove_name = names_test[idx]\n",
    "    remove_names_test.append(remove_name)\n",
    "\n",
    "print(remove_names_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in remove_names_train:\n",
    "    class_label = name.split('_')[0]\n",
    "    os.remove(os.path.join(image_path_train, class_label, name))\n",
    "    os.remove(os.path.join(mask_path_train, class_label, name))\n",
    "\n",
    "for name in remove_names_val:\n",
    "    class_label = name.split('_')[0]\n",
    "    os.remove(os.path.join(image_path_val, class_label, name))\n",
    "    os.remove(os.path.join(mask_path_val, class_label, name))\n",
    "\n",
    "for name in remove_names_test:\n",
    "    class_label = name.split('_')[0]\n",
    "    os.remove(os.path.join(image_path_test, class_label, name))\n",
    "    os.remove(os.path.join(mask_path_test, class_label, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finished"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b942636a785217c0b780635fcfa4dacafb5d46c802d84d4ffbd090c16749e713"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
