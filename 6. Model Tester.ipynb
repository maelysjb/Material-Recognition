{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, GlobalMaxPooling2D\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "SEED = 42\n",
    "import random \n",
    "random.seed(SEED)\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** Inputs **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which image folder name you want to use.\n",
    "image_folder_name = 'FMD_tvt'\n",
    "\n",
    "#image size\n",
    "img_size = (150, 150)\n",
    "\n",
    "#Batch Size of Data\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "Model_Test_Name = 'MobilNet.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup of Paths and Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fabric', 'foliage', 'glass', 'leather', 'metal', 'paper', 'plastic', 'stone', 'water', 'wood']\n"
     ]
    }
   ],
   "source": [
    "tvt_folders = ['train', 'val', 'test']\n",
    "im_folders = ['image', 'mask']\n",
    "\n",
    "Fmd_class_path = os.path.join(image_folder_name, tvt_folders[0], im_folders[0])\n",
    "classes = os.listdir(os.path.join(Fmd_class_path))\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path_test = os.path.join(image_folder_name, tvt_folders[2], im_folders[0])\n",
    "mask_path_test = os.path.join(image_folder_name, tvt_folders[2], im_folders[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Data and Make Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Three functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_load_image(x):\n",
    "    byte_img = tf.io.read_file(x) #Tensorflow way of loading in image\n",
    "    img = tf.io.decode_jpeg(byte_img)  #Need both lines of code\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset_imgs(tvt_folder, classes, img_size):\n",
    "    ds = tf.data.Dataset.list_files(os.path.join(image_folder_name, tvt_folder, 'image', classes[0], \"*.jpg\"), shuffle=False)\n",
    "    for i in range(len(classes)-1):\n",
    "        ds_class = tf.data.Dataset.list_files(os.path.join(image_folder_name, tvt_folder, 'image', classes[i+1], \"*.jpg\"), shuffle=False)\n",
    "        ds = ds.concatenate(ds_class)\n",
    "\n",
    "    ds = ds.map(fun_load_image)\n",
    "    ds = ds.map(lambda x: tf.image.resize(x, img_size))\n",
    "    ds = ds.map(lambda x: x/255)\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset_labels(image_path):\n",
    "    class_labels = []\n",
    "    for class_ in classes:\n",
    "        class_val = classes.index(class_)\n",
    "        num_in_class = len(os.listdir(os.path.join(image_path, class_)))\n",
    "        class_labels_ = [class_val]*num_in_class\n",
    "        class_labels = class_labels + class_labels_\n",
    "\n",
    "    label_ds = tf.data.Dataset.from_tensor_slices(class_labels)\n",
    "    return label_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = make_dataset_imgs(tvt_folders[2], classes, img_size)\n",
    "test_labels_ds = make_dataset_labels(image_path_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zipping and Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.data.Dataset.zip((test_ds, test_labels_ds))\n",
    "test = test.shuffle(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch and Prefetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.cache().batch(batch_size).prefetch(buffer_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_path = os.path.join('Models', Model_Test_Name)\n",
    "\n",
    "model = tf.keras.models.load_model(Model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.map(lambda a, b: a)\n",
    "y_test = test.map(lambda a, b: b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 2s 229ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_preds = []\n",
    "for lst in predictions:\n",
    "    # print(max(lst))\n",
    "    class_preds.append(np.where(lst == max(lst))[0][0])\n",
    "    \n",
    "y_test_true = []\n",
    "for elem in y_test:\n",
    "    for pred in elem.numpy():\n",
    "        y_test_true.append(pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "129\n",
      "class_accuracy = 0.645\n"
     ]
    }
   ],
   "source": [
    "comparison = []\n",
    "for i in range(len(y_test_true)):\n",
    "    # print(y_test_true[i], class_preds[i])\n",
    "    if y_test_true[i] == class_preds[i]:\n",
    "        comparison.append(1)\n",
    "    if y_test_true[i] != class_preds[i]:\n",
    "        comparison.append(0)\n",
    "\n",
    "print(f'Final Test Accuracy = {sum(comparison)/len(comparison)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b942636a785217c0b780635fcfa4dacafb5d46c802d84d4ffbd090c16749e713"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
